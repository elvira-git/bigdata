---
title: "fb app"
author: "Elvira Bekyrova"
date: "6/15/2017"
output: html_document
---

```{r}
#install.packages("devtools")
library(devtools)
#install_github("Rfacebook", "pablobarbera", subdir="Rfacebook")
library(Rfacebook)
```

```{r}
#fb_oauth <- fbOAuth(app_id="333908270376474", app_secret="9f46b836ad0ca8f1b06b378fb9e105fe",extended_permissions = TRUE)

#temporal token - insert your data
token<- "xxxx"
me<- getUsers("xxxxx", token, private_info = TRUE) #ID from Graph API Explorer

#long token - inster your data
fb_oauth<- fbOAuth(app_id="xxxxx",app_secret="xxxxx",extended_permissions = TRUE)

save(fb_oauth, file="fb_oauth")
load("fb_oauth")

#Let's get data about your profile
friends<- getFriends(token, simplify = FALSE) # all Facebook friends whose data is accessible
#simplify = TRUE: only name
#simplify = FALSE: name, gender, location, hometown, profile picture, relationship status

friends_data<- getUsers(friends$id, token, private_info = TRUE) #private_info = TRUE: relationship status, birthday, current location
table(friends_data$gender)

likes <- getLikes(user="me", token=fb_oauth) #my likes
head(likes)

friends<- getSQL("SELECT uid2 FROM friend WHERE uid1=me()", token=fb_oauth)
```

```{r}
#Let's analyze BIPM page
page <- getPage("masterbipm", token=fb_oauth, n=100)
#Most liked post
most_liked_post = page[which.max(page$likes_count), ]
likes_all_posts = page[page$likes_count, ]
```

Analysis of BBC, NY Times and SpaceX
```{r}
#Scrapping latest 1000 posts
bbcpage <- getPage("bbcnews", token=fb_oauth, n=1000) #BBC
nytpage <- getPage("nytimes", token=fb_oauth, n=1000) #NY Times 
spacexpage <- getPage("SpaceX", token=fb_oauth, n=1000) #SpaceX

#Scrapping 1000 BBC posts from 3-5 years ago
bbcpage_past <- getPage("bbcnews", token=fb_oauth, since="2014-01-31", until="2014-09-31", n=1000) 

#Sort by most liked posts
bbc_sort_by_likes = bbcpage[order(bbcpage$likes_count, decreasing = TRUE),] 

#Sort NY by most liked posts
ny_sort_by_likes = nytpage[order(nytpage$likes_count, decreasing = TRUE),] 

spacex_by_likes = spacexpage[order(spacexpage$likes_count, decreasing = TRUE),] 

#Remove unnecessary columns from BBC dataframe
bbc <- subset(bbcpage, select = -from_id)
bbc <- subset(bbc, select = -from_name)
bbc <- subset(bbc, select = -id)
bbc <- subset(bbc, select = -story)
bbc <- subset(bbc, select = -message)
bbc <- subset(bbc, select = -link)

#Add column with a length of the post
#bbc$post_len <- nchar(bbc$message)

#Add a column with a weekday
bbc$day <- weekdays(as.Date(bbc$created_time))

#Let's see the amount of rows per each post type
library(dplyr)
type_groups_bbc = bbcpage %>% group_by(type) %>% summarise(no_rows = length(type))

#Since "photo" is there just a few times, let's remove it from types
library(doBy)
bbc2 = bbc[- grep("photo", bbc$type),]
bbc2$type = as.character(bbc2$type)

#What types of posts bring the most likes on BBC?
likes_per_type = summaryBy(likes_count ~ type, data = bbc2, FUN = list(mean, max, min))
#Videos receive twice as much likes as links

#Let's see the amount of rows per each post type (BBC, 2014)
type_groups_bbc_past = bbcpage_past %>% group_by(type) %>% summarise(no_rows = length(type))

#Since music, event, status, link is there a not significat amount of times, let's remove it from types
bbc2_past = bbcpage_past[- grep("music", bbcpage_past$type),]
bbc2_past = bbc2_past[- grep("status", bbc2_past$type),]
bbc2_past = bbc2_past[- grep("event", bbc2_past$type),]
bbc2_past = bbc2_past[- grep("link", bbc2_past$type),]
bbc2_past$type = as.character(bbc2_past$type)

#What types of posts bring the most likes on BBC in 2014?
bbcpast_mostlikes = summaryBy(likes_count ~ type, data = bbc2_past, FUN = list(mean, max, min))

#Let's extract more posts for BBC
bbcpage5k <- getPage("bbcnews", token=fb_oauth, n=5000) 
bbcpage5k$day <- weekdays(as.Date(bbcpage5k$created_time))

#Amount of posts per day
likes_per_day = summaryBy(likes_count ~ day, data = bbcpage5k, FUN = list(mean, max, min))
post_day = bbc %>% group_by(day) %>% summarise(no_rows = length(day))

#Let's plot in which day there are more likes
library(plotly)

plot_ly(
  x = likes_per_day$day,
  y = likes_per_day$likes_count.mean,
  name = "Likes per day",
  type = "bar",
)

#Extract rows only with Sunday
bbcsunday <- bbcpage5k[ which(bbcpage5k$day=='Sunday'), ]

#Convert time to a more suitable format
bbcsunday$time <- strptime(as.character(bbcsunday$created_time), "%Y-%m-%dT%H:%M:%S+0000")

#Extract hours
bbcsunday$hour = format(as.POSIXct(bbcsunday$time,format="%H:%M:%S"),"%H")
likes_per_hour = summaryBy(likes_count ~ hour, data = bbcsunday, FUN = list(mean, max, min))

#Most popular time on Sunday (EDT)
plot_ly(
  x = likes_per_hour$hour,
  y = likes_per_hour$likes_count.mean,
  name = "Likes per day",
  type = "bar",
)

#write.csv(bbc, file = "bbcposts.csv")

```

```{r}
#Let's build a decision tree showing us what likes depend on the most
DecisionTree <- rpart(likes_count ~ type + day, data=bbc, method="anova", control=rpart.control(minsplit=150, cp=0.001))
#Plot tree 
plot(DecisionTree, uniform=TRUE, main="Classification Type/Day", margin=0.2)
text(DecisionTree, use.n=TRUE, all=TRUE, cex=.5)
```


```{r}
library(doBy)
bbc2 = bbc[- grep("photo", bbc$type),]
bbc2$type = as.character(bbc2$type)

#What types of posts bring the most likes on SpaceX?
summaryBy(likes_count ~ type, data = spacexpage, FUN = list(mean, max, min, median, sd))

#What types of posts bring the most likes on BBC in 2014?
tmp = summaryBy(likes_count ~ type, data = bbcpage_past, FUN = list(mean, max, min, median, sd))
library(dplyr)
type_groups_bbc_past = bbcpage_past %>% group_by(type) %>% summarise(no_rows = length(type))

counts <- bbcpage_past(bbcpage_past$gear)
barplot(counts)
```



```{r}
page_matrix <- as.matrix(page)
rows = nrow(page_matrix)

for (i in 1:26) {
  k[i] = page[i,7]
}

# Collecting all the commments from all the 100 posts
i = 0
for (i in 1:26)
{
  
# Get upto 1000 comments for each post
post <- getPost(k[i], token=fb_oauth, n = 1000, likes = TRUE, comments = TRUE)
comments<- post$comments
# Append the comments to a single data frame
allcomments<- rbind(allcomments, comments)
}
k = 0


```